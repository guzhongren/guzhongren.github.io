<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>K8s 1.15.0 安装记录 - 谷中仁的博客</title><meta name=Description content="最近的总结或者思考..."><meta property="og:url" content="https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/">
<meta property="og:site_name" content="谷中仁的博客"><meta property="og:title" content="K8s 1.15.0 安装记录"><meta property="og:description" content='环境 hostname ip system master 192.168.33.10 CentOS7 node1 192.168.33.11 CentOS7 node2 192.168.33.12 CentOS7 node3 192.168.33.13 CentOS7 node4 192.168.33.14 CentOS7 node5 192.168.33.15 CentOS7 所有节点上操作 [root@master install]# cat preENV.sh #!/bin/bash # 关闭防火墙 systemctl stop firewalld && systemctl disable firewalld # 关闭 SELINUX setenforce 0 && sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config # 关闭 Swap swapoff -a && sed -i "s/\/dev\/mapper\/centos-swap/\#\/dev\/mapper\/centos-swap/g" /etc/fstab [root@master ~]# vim /etc/sysctl.d/k8s.conf [root@master ~]# cat /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 [root@master ~]# modprobe br_netfilter && sysctl -p /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 [root@master ~]# wget -O /etc/yum.repos.d/CentOS7-Aliyun.repo http://mirrors.aliyun.com/repo/Centos-7.repo --2019-06-30 04:26:32-- http://mirrors.aliyun.com/repo/Centos-7.repo Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 116.177.250.229, 116.177.250.233, 60.28.226.4, ... Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|116.177.250.229|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 2523 (2.5K) [application/octet-stream] Saving to: ‘/etc/yum.repos.d/CentOS7-Aliyun.repo’ 100%[============================================================================>] 2,523 --.-K/s in 0s 2019-06-30 04:26:32 (296 MB/s) - ‘/etc/yum.repos.d/CentOS7-Aliyun.repo’ saved [2523/2523] root@master ~]# sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 [root@master ~]# sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo [root@master ~]# yum install docker-ce -y [root@master ~]# systemctl enable docker && systemctl start docker Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. [root@master ~]# mkdir -p /etc/docker [root@master ~]# sudo tee /etc/docker/daemon.json <<-&#39;EOF&#39; { "registry-mirrors": ["https://gmjjwogo.mirror.aliyuncs.com"], "exec-opts": ["native.cgroupdriver=systemd"] } EOF { "registry-mirrors": ["https://gmjjwogo.mirror.aliyuncs.com"], "exec-opts": ["native.cgroupdriver=systemd"] } [root@master ~]# sudo systemctl daemon-reload && sudo systemctl restart docker [root@master ~]# docker info |grep Cgroup Cgroup Driver: systemd [root@master ~]# # kube-proxy 开启 ipvs 的前置条件 [root@master ~]# cat > /etc/sysconfig/modules/ipvs.modules <<EOF #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF [root@master ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4 ip_vs_sh 12688 0 ip_vs_wrr 12697 0 ip_vs_rr 12600 0 ip_vs 145497 6 ip_vs_rr,ip_vs_sh,ip_vs_wrr nf_conntrack_ipv4 15053 2 nf_defrag_ipv4 12729 1 nf_conntrack_ipv4 nf_conntrack 133095 7 ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_ipv4 libcrc32c 12644 4 xfs,ip_vs,nf_nat,nf_conntrack [root@master ~]# # 安装 kubernetes 初始化工具 [root@master ~]# # 使用阿里云的 kubernetes 源 [root@master ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF [root@master ~]# # 安装 k8s 工具 1.15 版本 [root@master ~]# yum install -y kubelet kubeadm kubectl Installed: kubeadm.x86_64 0:1.15.0-0 kubectl.x86_64 0:1.15.0-0 kubelet.x86_64 0:1.15.0-0 Dependency Installed: conntrack-tools.x86_64 0:1.4.4-4.el7 cri-tools.x86_64 0:1.12.0-0 kubernetes-cni.x86_64 0:0.7.5-0 libnetfilter_cthelper.x86_64 0:1.0.0-9.el7 libnetfilter_cttimeout.x86_64 0:1.0.0-6.el7 libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 socat.x86_64 0:1.7.3.2-2.el7 Complete! [root@master ~]# # 启动 kubelet [root@master ~]# systemctl enable kubelet && systemctl start kubelet Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. [root@master ~]# 主节点操作 [root@master install]# vim installK8sMasterImage.sh [root@master install]# cat installK8sMasterImage.sh #!/bin/bash set -e KUBE_VERSION=v1.15.0 KUBE_PAUSE_VERSION=3.1 ETCD_VERSION=3.3.10 CORE_DNS_VERSION=1.3.1 GCR_URL=k8s.gcr.io ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers images=(kube-proxy:${KUBE_VERSION} kube-scheduler:${KUBE_VERSION} kube-controller-manager:${KUBE_VERSION} kube-apiserver:${KUBE_VERSION} pause:${KUBE_PAUSE_VERSION} etcd:${ETCD_VERSION} coredns:${CORE_DNS_VERSION}) for imageName in ${images[@]} ; do docker pull $ALIYUN_URL/$imageName docker tag $ALIYUN_URL/$imageName $GCR_URL/$imageName docker rmi $ALIYUN_URL/$imageName done [root@master install]# chmod +x installK8sMasterImage.sh && ./installK8sMasterImage.sh root@master install]# kubeadm init --kubernetes-version=v1.15.0 --apiserver-advertise-address=192.168.33.10 --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.15.0 [preflight] Running pre-flight checks [WARNING Hostname]: hostname "master" could not be reached [WARNING Hostname]: hostname "master": lookup master on 10.0.2.3:53: no such host [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39; [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env" [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder "/etc/kubernetes/pki" [certs] Generating "front-proxy-ca" certificate and key [certs] Generating "front-proxy-client" certificate and key [certs] Generating "ca" certificate and key [certs] Generating "apiserver" certificate and key [certs] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.33.10] [certs] Generating "apiserver-kubelet-client" certificate and key [certs] Generating "etcd/ca" certificate and key [certs] Generating "etcd/server" certificate and key [certs] etcd/server serving cert is signed for DNS names [master localhost] and IPs [192.168.33.10 127.0.0.1 ::1] [certs] Generating "etcd/healthcheck-client" certificate and key [certs] Generating "apiserver-etcd-client" certificate and key [certs] Generating "etcd/peer" certificate and key [certs] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.33.10 127.0.0.1 ::1] [certs] Generating "sa" key and public key [kubeconfig] Using kubeconfig folder "/etc/kubernetes" [kubeconfig] Writing "admin.conf" kubeconfig file [kubeconfig] Writing "kubelet.conf" kubeconfig file [kubeconfig] Writing "controller-manager.conf" kubeconfig file [kubeconfig] Writing "scheduler.conf" kubeconfig file [control-plane] Using manifest folder "/etc/kubernetes/manifests" [control-plane] Creating static Pod manifest for "kube-apiserver" [control-plane] Creating static Pod manifest for "kube-controller-manager" [control-plane] Creating static Pod manifest for "kube-scheduler" [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s [apiclient] All control plane components are healthy after 26.502984 seconds [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace [kubelet] Creating a ConfigMap "kubelet-config-1.15" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master as control-plane by adding the label "node-role.kubernetes.io/master=&#39;&#39;" [mark-control-plane] Marking the node master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: z1uxfl.z8l2uo9v8x3dtdcu [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.33.10:6443 --token z1uxfl.z8l2uo9v8x3dtdcu \ --discovery-token-ca-cert-hash sha256:5c725b5b384221d25aed03a02a142fe2442d76f6362673b72f349abffb18b6f2 [root@master ~]# [root@master ~]# mkdir -p $HOME/.kube [root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config [root@master ~]# kubectl get pod -n kube-system -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES coredns-5c98db65d4-9g7dj 0/1 Pending 0 39s <none> <none> <none> <none> coredns-5c98db65d4-f6h7d 0/1 Pending 0 39s <none> <none> <none> <none> etcd-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> kube-apiserver-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> kube-controller-manager-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> kube-proxy-n9tql 1/1 Running 0 39s 10.0.2.15 master <none> <none> kube-scheduler-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> [root@master ~]# wget https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml --2019-06-30 06:47:53-- https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.228.133 Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.228.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 12306 (12K) [text/plain] Saving to: ‘kube-flannel.yml’ 100%[==============================================================================================>] 12,306 51.3KB/s in 0.2s 2019-06-30 06:47:57 (51.3 KB/s) - ‘kube-flannel.yml’ saved [12306/12306] [root@master install]# ll total 24 -rwxr-xr-x. 1 root root 580 Jun 30 05:21 installK8sMasterImage.sh -rw-r--r--. 1 root root 12306 Jun 30 05:26 kube-flannel.yml -rwxr-xr-x. 1 root root 294 Jun 30 04:20 preENV.sh [root@master install]# kubectl apply -f kube-flannel.yml podsecuritypolicy.extensions/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.extensions/kube-flannel-ds-amd64 created daemonset.extensions/kube-flannel-ds-arm64 created daemonset.extensions/kube-flannel-ds-arm created daemonset.extensions/kube-flannel-ds-ppc64le created daemonset.extensions/kube-fla[root@master ~]# kubectl get pod -n kube-system -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES coredns-5c98db65d4-9g7dj 1/1 Running 0 5m42s 10.244.0.3 master <none> <none> coredns-5c98db65d4-f6h7d 1/1 Running 0 5m42s 10.244.0.2 master <none> <none> etcd-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> kube-apiserver-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> kube-controller-manager-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> kube-flannel-ds-amd64-lbprc 1/1 Running 0 84s 10.0.2.15 master <none> <none> kube-proxy-n9tql 1/1 Running 0 5m42s 10.0.2.15 master <none> <none> kube-scheduler-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> [root@master install]# # 查看当前集群状态 [root@master ~]# kubectl get node -A NAME STATUS ROLES AGE VERSION master Ready master 6m29s v1.15.0 [root@master ~]# 各 Node 节点上处理 [root@node2 install]# vim installK8sNodeImage.sh [root@node5 install]# cat installK8sNodeImage.sh #!/bin/bash set -e KUBE_VERSION=v1.15.0 KUBE_PAUSE_VERSION=3.1 CORE_DNS_VERSION=1.3.1 GCR_URL=k8s.gcr.io ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers images=(kube-proxy:${KUBE_VERSION} pause:${KUBE_PAUSE_VERSION} coredns:${CORE_DNS_VERSION}) for imageName in ${images[@]} ; do docker pull $ALIYUN_URL/$imageName docker tag $ALIYUN_URL/$imageName $GCR_URL/$imageName docker rmi $ALIYUN_URL/$imageName done [root@node1 ~]# chmod +x installK8sNodeImage.sh && ./installK8sNodeImage.sh v1.15.0: Pulling from google_containers/kube-proxy 39fafc05754f: Pull complete db3f71d0eb90: Pull complete b593bfa65f6f: Pull complete Digest: sha256:7b94921f1c64876d3663698ade724fce79b417b32f0e1053976ca68a18fc0cba Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.0 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.0 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy@sha256:7b94921f1c64876d3663698ade724fce79b417b32f0e1053976ca68a18fc0cba 3.1: Pulling from google_containers/pause cf9202429979: Pull complete Digest: sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/pause@sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca 1.3.1: Pulling from google_containers/coredns e0daa8927b68: Pull complete 3928e47de029: Pull complete Digest: sha256:638adb0319813f2479ba3642bbe37136db8cf363b48fb3eb7dc8db634d8d5a5b Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns@sha256:638adb0319813f2479ba3642bbe37136db8cf363b48fb3eb7dc8db634d8d5a5b [root@node1 ~]# [root@node5 install]# # Node 加入集群 [root@node1 install]# kubeadm join 192.168.33.10:6443 --token sofcoc.j1it9gvn4uxpduo5 \ > --discovery-token-ca-cert-hash sha256:3a9b79bd92f66a6284322ade27732932888c0f99884596d5f2c9a03d272e475b [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.15" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env" [kubelet-start] Activating the kubelet service [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster. [root@node1 install]# master 节点操作 [root@master ~]# #将 master 节点也作为工作节点进行 pod 部署 [root@master ~]# kubectl taint nodes master node-role.kubernetes.io/master- node/master untainted 打 label [root@master temp]# kubectl label node master nodename=master node/master labeled [root@master temp]# kubectl label node node1 nodename=node1 node/node1 labeled [root@master temp]# kubectl label node node2 nodename=node2 node/node2 labeled [root@master temp]# kubectl label node node3 nodename=node3 node/node3 labeled [root@master temp]# kubectl label node node4 nodename=node4 node/node4 labeled [root@master temp]# kubectl label node node5 nodename=node5 node/node5 labeled 测试 vim nginx-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: web protocol: TCP nodeSelector: nodename: master --- apiVersion: v1 kind: Service metadata: name: nginx-service labels: app: nginx spec: ports: - port: 80 targetPort: 8080 name: web selector: app-name: nginx --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: nginx namespace: default spec: rules: - host: c4.k8s.com http: paths: - path: /nginx backend: serviceName: nginx-service servicePort: 8080 [root@master temp]# kubectl apply -f nginx-deployment.yaml deployment.apps/nginx-deployment created service/nginx-service created ingress.extensions/nginx created [root@master temp]# kubectl get service/nginx-service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-service ClusterIP 10.100.2.78 <none> 80/TCP 38s [root@master temp]# kubectl get ing NAME HOSTS ADDRESS PORTS AGE nginx c4.k8s.com 80 4m5s [root@master temp]# wget c4.k8s.com --2019-06-30 07:12:18-- http://c4.k8s.com/ Resolving c4.k8s.com (c4.k8s.com)... 208.73.211.177, 208.73.210.202, 208.73.211.165, ... Connecting to c4.k8s.com (c4.k8s.com)|208.73.211.177|:80... connected. HTTP request sent, awaiting response... 302 Found : Moved Temporarily Location: http://1223.dragonparking.com/?site=c4.k8s.com [following] --2019-06-30 07:12:19-- http://1223.dragonparking.com/?site=c4.k8s.com Resolving 1223.dragonparking.com (1223.dragonparking.com)... 46.51.238.1 Connecting to 1223.dragonparking.com (1223.dragonparking.com)|46.51.238.1|:80... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: http://park.zunmi.cn/?acct=1223&amp;site=c4.k8s.com [following] --2019-06-30 07:12:21-- http://park.zunmi.cn/?acct=1223&amp;site=c4.k8s.com Resolving park.zunmi.cn (park.zunmi.cn)... 52.197.205.2 Connecting to park.zunmi.cn (park.zunmi.cn)|52.197.205.2|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020 [text/html] Saving to: ‘index.html’ 100%[======================================================================================================================================>] 1,020 --.-K/s in 0s 2019-06-30 07:12:22 (93.5 MB/s) - ‘index.html’ saved [1020/1020] [root@master temp]# ll total 8 -rw-r--r--. 1 root root 1020 May 6 23:28 index.html -rw-r--r--. 1 root root 908 Jun 30 07:07 nginx-deployment.yaml [root@master temp]# kubectl delete -f nginx-deployment.yaml deployment.apps "nginx-deployment" deleted service "nginx-service" deleted ingress.extensions "nginx" deleted'><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-06-30T19:46:11+08:00"><meta property="article:modified_time" content="2019-06-30T19:46:11+08:00"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Install"><meta property="article:tag" content="Cluster"><meta property="article:tag" content="Nginx"><meta property="article:tag" content="Service"><meta property="og:image" content="https://guzhongren.github.io/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://guzhongren.github.io/logo.png"><meta name=twitter:title content="K8s 1.15.0 安装记录"><meta name=twitter:description content='环境 hostname ip system master 192.168.33.10 CentOS7 node1 192.168.33.11 CentOS7 node2 192.168.33.12 CentOS7 node3 192.168.33.13 CentOS7 node4 192.168.33.14 CentOS7 node5 192.168.33.15 CentOS7 所有节点上操作 [root@master install]# cat preENV.sh #!/bin/bash # 关闭防火墙 systemctl stop firewalld && systemctl disable firewalld # 关闭 SELINUX setenforce 0 && sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config # 关闭 Swap swapoff -a && sed -i "s/\/dev\/mapper\/centos-swap/\#\/dev\/mapper\/centos-swap/g" /etc/fstab [root@master ~]# vim /etc/sysctl.d/k8s.conf [root@master ~]# cat /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 [root@master ~]# modprobe br_netfilter && sysctl -p /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 [root@master ~]# wget -O /etc/yum.repos.d/CentOS7-Aliyun.repo http://mirrors.aliyun.com/repo/Centos-7.repo --2019-06-30 04:26:32-- http://mirrors.aliyun.com/repo/Centos-7.repo Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 116.177.250.229, 116.177.250.233, 60.28.226.4, ... Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|116.177.250.229|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 2523 (2.5K) [application/octet-stream] Saving to: ‘/etc/yum.repos.d/CentOS7-Aliyun.repo’ 100%[============================================================================>] 2,523 --.-K/s in 0s 2019-06-30 04:26:32 (296 MB/s) - ‘/etc/yum.repos.d/CentOS7-Aliyun.repo’ saved [2523/2523] root@master ~]# sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 [root@master ~]# sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo [root@master ~]# yum install docker-ce -y [root@master ~]# systemctl enable docker && systemctl start docker Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. [root@master ~]# mkdir -p /etc/docker [root@master ~]# sudo tee /etc/docker/daemon.json <<-&#39;EOF&#39; { "registry-mirrors": ["https://gmjjwogo.mirror.aliyuncs.com"], "exec-opts": ["native.cgroupdriver=systemd"] } EOF { "registry-mirrors": ["https://gmjjwogo.mirror.aliyuncs.com"], "exec-opts": ["native.cgroupdriver=systemd"] } [root@master ~]# sudo systemctl daemon-reload && sudo systemctl restart docker [root@master ~]# docker info |grep Cgroup Cgroup Driver: systemd [root@master ~]# # kube-proxy 开启 ipvs 的前置条件 [root@master ~]# cat > /etc/sysconfig/modules/ipvs.modules <<EOF #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF [root@master ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4 ip_vs_sh 12688 0 ip_vs_wrr 12697 0 ip_vs_rr 12600 0 ip_vs 145497 6 ip_vs_rr,ip_vs_sh,ip_vs_wrr nf_conntrack_ipv4 15053 2 nf_defrag_ipv4 12729 1 nf_conntrack_ipv4 nf_conntrack 133095 7 ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_ipv4 libcrc32c 12644 4 xfs,ip_vs,nf_nat,nf_conntrack [root@master ~]# # 安装 kubernetes 初始化工具 [root@master ~]# # 使用阿里云的 kubernetes 源 [root@master ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF [root@master ~]# # 安装 k8s 工具 1.15 版本 [root@master ~]# yum install -y kubelet kubeadm kubectl Installed: kubeadm.x86_64 0:1.15.0-0 kubectl.x86_64 0:1.15.0-0 kubelet.x86_64 0:1.15.0-0 Dependency Installed: conntrack-tools.x86_64 0:1.4.4-4.el7 cri-tools.x86_64 0:1.12.0-0 kubernetes-cni.x86_64 0:0.7.5-0 libnetfilter_cthelper.x86_64 0:1.0.0-9.el7 libnetfilter_cttimeout.x86_64 0:1.0.0-6.el7 libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 socat.x86_64 0:1.7.3.2-2.el7 Complete! [root@master ~]# # 启动 kubelet [root@master ~]# systemctl enable kubelet && systemctl start kubelet Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service. [root@master ~]# 主节点操作 [root@master install]# vim installK8sMasterImage.sh [root@master install]# cat installK8sMasterImage.sh #!/bin/bash set -e KUBE_VERSION=v1.15.0 KUBE_PAUSE_VERSION=3.1 ETCD_VERSION=3.3.10 CORE_DNS_VERSION=1.3.1 GCR_URL=k8s.gcr.io ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers images=(kube-proxy:${KUBE_VERSION} kube-scheduler:${KUBE_VERSION} kube-controller-manager:${KUBE_VERSION} kube-apiserver:${KUBE_VERSION} pause:${KUBE_PAUSE_VERSION} etcd:${ETCD_VERSION} coredns:${CORE_DNS_VERSION}) for imageName in ${images[@]} ; do docker pull $ALIYUN_URL/$imageName docker tag $ALIYUN_URL/$imageName $GCR_URL/$imageName docker rmi $ALIYUN_URL/$imageName done [root@master install]# chmod +x installK8sMasterImage.sh && ./installK8sMasterImage.sh root@master install]# kubeadm init --kubernetes-version=v1.15.0 --apiserver-advertise-address=192.168.33.10 --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.15.0 [preflight] Running pre-flight checks [WARNING Hostname]: hostname "master" could not be reached [WARNING Hostname]: hostname "master": lookup master on 10.0.2.3:53: no such host [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39; [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env" [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder "/etc/kubernetes/pki" [certs] Generating "front-proxy-ca" certificate and key [certs] Generating "front-proxy-client" certificate and key [certs] Generating "ca" certificate and key [certs] Generating "apiserver" certificate and key [certs] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.33.10] [certs] Generating "apiserver-kubelet-client" certificate and key [certs] Generating "etcd/ca" certificate and key [certs] Generating "etcd/server" certificate and key [certs] etcd/server serving cert is signed for DNS names [master localhost] and IPs [192.168.33.10 127.0.0.1 ::1] [certs] Generating "etcd/healthcheck-client" certificate and key [certs] Generating "apiserver-etcd-client" certificate and key [certs] Generating "etcd/peer" certificate and key [certs] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.33.10 127.0.0.1 ::1] [certs] Generating "sa" key and public key [kubeconfig] Using kubeconfig folder "/etc/kubernetes" [kubeconfig] Writing "admin.conf" kubeconfig file [kubeconfig] Writing "kubelet.conf" kubeconfig file [kubeconfig] Writing "controller-manager.conf" kubeconfig file [kubeconfig] Writing "scheduler.conf" kubeconfig file [control-plane] Using manifest folder "/etc/kubernetes/manifests" [control-plane] Creating static Pod manifest for "kube-apiserver" [control-plane] Creating static Pod manifest for "kube-controller-manager" [control-plane] Creating static Pod manifest for "kube-scheduler" [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s [apiclient] All control plane components are healthy after 26.502984 seconds [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace [kubelet] Creating a ConfigMap "kubelet-config-1.15" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master as control-plane by adding the label "node-role.kubernetes.io/master=&#39;&#39;" [mark-control-plane] Marking the node master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: z1uxfl.z8l2uo9v8x3dtdcu [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.33.10:6443 --token z1uxfl.z8l2uo9v8x3dtdcu \ --discovery-token-ca-cert-hash sha256:5c725b5b384221d25aed03a02a142fe2442d76f6362673b72f349abffb18b6f2 [root@master ~]# [root@master ~]# mkdir -p $HOME/.kube [root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config [root@master ~]# kubectl get pod -n kube-system -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES coredns-5c98db65d4-9g7dj 0/1 Pending 0 39s <none> <none> <none> <none> coredns-5c98db65d4-f6h7d 0/1 Pending 0 39s <none> <none> <none> <none> etcd-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> kube-apiserver-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> kube-controller-manager-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> kube-proxy-n9tql 1/1 Running 0 39s 10.0.2.15 master <none> <none> kube-scheduler-master 1/1 Running 0 57s 10.0.2.15 master <none> <none> [root@master ~]# wget https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml --2019-06-30 06:47:53-- https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.228.133 Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.228.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 12306 (12K) [text/plain] Saving to: ‘kube-flannel.yml’ 100%[==============================================================================================>] 12,306 51.3KB/s in 0.2s 2019-06-30 06:47:57 (51.3 KB/s) - ‘kube-flannel.yml’ saved [12306/12306] [root@master install]# ll total 24 -rwxr-xr-x. 1 root root 580 Jun 30 05:21 installK8sMasterImage.sh -rw-r--r--. 1 root root 12306 Jun 30 05:26 kube-flannel.yml -rwxr-xr-x. 1 root root 294 Jun 30 04:20 preENV.sh [root@master install]# kubectl apply -f kube-flannel.yml podsecuritypolicy.extensions/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.extensions/kube-flannel-ds-amd64 created daemonset.extensions/kube-flannel-ds-arm64 created daemonset.extensions/kube-flannel-ds-arm created daemonset.extensions/kube-flannel-ds-ppc64le created daemonset.extensions/kube-fla[root@master ~]# kubectl get pod -n kube-system -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES coredns-5c98db65d4-9g7dj 1/1 Running 0 5m42s 10.244.0.3 master <none> <none> coredns-5c98db65d4-f6h7d 1/1 Running 0 5m42s 10.244.0.2 master <none> <none> etcd-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> kube-apiserver-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> kube-controller-manager-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> kube-flannel-ds-amd64-lbprc 1/1 Running 0 84s 10.0.2.15 master <none> <none> kube-proxy-n9tql 1/1 Running 0 5m42s 10.0.2.15 master <none> <none> kube-scheduler-master 1/1 Running 0 6m 10.0.2.15 master <none> <none> [root@master install]# # 查看当前集群状态 [root@master ~]# kubectl get node -A NAME STATUS ROLES AGE VERSION master Ready master 6m29s v1.15.0 [root@master ~]# 各 Node 节点上处理 [root@node2 install]# vim installK8sNodeImage.sh [root@node5 install]# cat installK8sNodeImage.sh #!/bin/bash set -e KUBE_VERSION=v1.15.0 KUBE_PAUSE_VERSION=3.1 CORE_DNS_VERSION=1.3.1 GCR_URL=k8s.gcr.io ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers images=(kube-proxy:${KUBE_VERSION} pause:${KUBE_PAUSE_VERSION} coredns:${CORE_DNS_VERSION}) for imageName in ${images[@]} ; do docker pull $ALIYUN_URL/$imageName docker tag $ALIYUN_URL/$imageName $GCR_URL/$imageName docker rmi $ALIYUN_URL/$imageName done [root@node1 ~]# chmod +x installK8sNodeImage.sh && ./installK8sNodeImage.sh v1.15.0: Pulling from google_containers/kube-proxy 39fafc05754f: Pull complete db3f71d0eb90: Pull complete b593bfa65f6f: Pull complete Digest: sha256:7b94921f1c64876d3663698ade724fce79b417b32f0e1053976ca68a18fc0cba Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.0 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.0 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy@sha256:7b94921f1c64876d3663698ade724fce79b417b32f0e1053976ca68a18fc0cba 3.1: Pulling from google_containers/pause cf9202429979: Pull complete Digest: sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/pause@sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca 1.3.1: Pulling from google_containers/coredns e0daa8927b68: Pull complete 3928e47de029: Pull complete Digest: sha256:638adb0319813f2479ba3642bbe37136db8cf363b48fb3eb7dc8db634d8d5a5b Status: Downloaded newer image for registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns@sha256:638adb0319813f2479ba3642bbe37136db8cf363b48fb3eb7dc8db634d8d5a5b [root@node1 ~]# [root@node5 install]# # Node 加入集群 [root@node1 install]# kubeadm join 192.168.33.10:6443 --token sofcoc.j1it9gvn4uxpduo5 \ > --discovery-token-ca-cert-hash sha256:3a9b79bd92f66a6284322ade27732932888c0f99884596d5f2c9a03d272e475b [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.15" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env" [kubelet-start] Activating the kubelet service [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster. [root@node1 install]# master 节点操作 [root@master ~]# #将 master 节点也作为工作节点进行 pod 部署 [root@master ~]# kubectl taint nodes master node-role.kubernetes.io/master- node/master untainted 打 label [root@master temp]# kubectl label node master nodename=master node/master labeled [root@master temp]# kubectl label node node1 nodename=node1 node/node1 labeled [root@master temp]# kubectl label node node2 nodename=node2 node/node2 labeled [root@master temp]# kubectl label node node3 nodename=node3 node/node3 labeled [root@master temp]# kubectl label node node4 nodename=node4 node/node4 labeled [root@master temp]# kubectl label node node5 nodename=node5 node/node5 labeled 测试 vim nginx-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: web protocol: TCP nodeSelector: nodename: master --- apiVersion: v1 kind: Service metadata: name: nginx-service labels: app: nginx spec: ports: - port: 80 targetPort: 8080 name: web selector: app-name: nginx --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: nginx namespace: default spec: rules: - host: c4.k8s.com http: paths: - path: /nginx backend: serviceName: nginx-service servicePort: 8080 [root@master temp]# kubectl apply -f nginx-deployment.yaml deployment.apps/nginx-deployment created service/nginx-service created ingress.extensions/nginx created [root@master temp]# kubectl get service/nginx-service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-service ClusterIP 10.100.2.78 <none> 80/TCP 38s [root@master temp]# kubectl get ing NAME HOSTS ADDRESS PORTS AGE nginx c4.k8s.com 80 4m5s [root@master temp]# wget c4.k8s.com --2019-06-30 07:12:18-- http://c4.k8s.com/ Resolving c4.k8s.com (c4.k8s.com)... 208.73.211.177, 208.73.210.202, 208.73.211.165, ... Connecting to c4.k8s.com (c4.k8s.com)|208.73.211.177|:80... connected. HTTP request sent, awaiting response... 302 Found : Moved Temporarily Location: http://1223.dragonparking.com/?site=c4.k8s.com [following] --2019-06-30 07:12:19-- http://1223.dragonparking.com/?site=c4.k8s.com Resolving 1223.dragonparking.com (1223.dragonparking.com)... 46.51.238.1 Connecting to 1223.dragonparking.com (1223.dragonparking.com)|46.51.238.1|:80... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: http://park.zunmi.cn/?acct=1223&amp;site=c4.k8s.com [following] --2019-06-30 07:12:21-- http://park.zunmi.cn/?acct=1223&amp;site=c4.k8s.com Resolving park.zunmi.cn (park.zunmi.cn)... 52.197.205.2 Connecting to park.zunmi.cn (park.zunmi.cn)|52.197.205.2|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020 [text/html] Saving to: ‘index.html’ 100%[======================================================================================================================================>] 1,020 --.-K/s in 0s 2019-06-30 07:12:22 (93.5 MB/s) - ‘index.html’ saved [1020/1020] [root@master temp]# ll total 8 -rw-r--r--. 1 root root 1020 May 6 23:28 index.html -rw-r--r--. 1 root root 908 Jun 30 07:07 nginx-deployment.yaml [root@master temp]# kubectl delete -f nginx-deployment.yaml deployment.apps "nginx-deployment" deleted service "nginx-service" deleted ingress.extensions "nginx" deleted'><meta name=application-name content="谷中仁的博客"><meta name=apple-mobile-web-app-title content="谷中仁的博客"><meta name=referrer content="no-referrer"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/><link rel=prev href=https://guzhongren.github.io/2019/06/harbor-%E5%AE%89%E8%A3%85%E5%B0%8F%E8%AE%B0.zh/><link rel=next href=https://guzhongren.github.io/2019/09/golang-with-sqllite-practice.zh/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"K8s 1.15.0 安装记录","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/guzhongren.github.io\/2019\/06\/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh\/"},"image":["https:\/\/guzhongren.github.io\/images\/avatar.png"],"genre":"posts","keywords":"kubernetes, install, cluster, nginx, service","wordcount":2077,"url":"https:\/\/guzhongren.github.io\/2019\/06\/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh\/","datePublished":"2019-06-30T19:46:11+08:00","dateModified":"2019-06-30T19:46:11+08:00","license":"Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"guzhongren","logo":"https:\/\/guzhongren.github.io\/logo.png"},"author":{"@type":"Person","name":"谷中仁"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script>const query=window.matchMedia("(prefers-color-scheme: dark)");function applyTheme(){let e=window.localStorage?.getItem("theme")||"auto",t=e==="dark"||e==="auto"&&query.matches;document.body.setAttribute("theme",t?"dark":"light"),document.body.setAttribute("cfg-theme",e)}applyTheme(),query.addEventListener("change",applyTheme)</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=谷中仁的博客><img class="lazyload logo" src=/svg/loading.min.svg data-src=/images/avatar.svg data-srcset="/images/avatar.svg, /images/avatar.svg 1.5x, /images/avatar.svg 2x" data-sizes=auto alt=/images/avatar.svg title=/images/avatar.svg>谷中仁的博客</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/tags/ title=Tags>Tags </a><a class=menu-item href=/categories/ title=Categories>Categories </a><a class=menu-item href=/slides/ title=Slides>Slides </a><a class=menu-item href="https://www.figma.com/file/7EzjLtMRXKcaJrGEmudLwC/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1?node-id=0%3A1" title=知识图谱 rel="noopener noreffer" target=_blank>知识图谱 </a><a class=menu-item href=/about/ title=关于>关于 </a><a class=menu-item href=https://github.com/guzhongren title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> GitHub </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=谷中仁的博客><img class="lazyload logo" src=/svg/loading.min.svg data-src=/images/avatar.svg data-srcset="/images/avatar.svg, /images/avatar.svg 1.5x, /images/avatar.svg 2x" data-sizes=auto alt=/images/avatar.svg title=/images/avatar.svg>谷中仁的博客</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/tags/ title=Tags>Tags</a><a class=menu-item href=/categories/ title=Categories>Categories</a><a class=menu-item href=/slides/ title=Slides>Slides</a><a class=menu-item href="https://www.figma.com/file/7EzjLtMRXKcaJrGEmudLwC/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1?node-id=0%3A1" title=知识图谱 rel="noopener noreffer" target=_blank>知识图谱</a><a class=menu-item href=/about/ title=关于>关于</a><a class=menu-item href=https://github.com/guzhongren title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i>GitHub</a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">K8s 1.15.0 安装记录</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://guzhongren.github.io title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>谷中仁</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/kubernetes/><i class="far fa-folder fa-fw" aria-hidden=true></i>Kubernetes</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2019-06-30>2019-06-30</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;约 2077 字&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;预计阅读 5 分钟&nbsp;</div></div><div class=featured-image><img class=lazyload src=/svg/loading.min.svg data-src="https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260" data-srcset="https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260, https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260 1.5x, https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260 2x" data-sizes=auto alt="https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260" title="https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260"></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#环境>环境</a></li><li><a href=#所有节点上操作>所有节点上操作</a></li><li><a href=#主节点操作>主节点操作</a></li><li><a href=#各-node-节点上处理>各 Node 节点上处理</a></li><li><a href=#master-节点操作>master 节点操作</a></li><li><a href=#打-label>打 label</a></li><li><a href=#测试>测试</a></li></ul></nav></div></div><div class=content id=content><h2 id=环境>环境</h2><table><thead><tr><th>hostname</th><th style=text-align:left>ip</th><th style=text-align:left>system</th><th></th></tr></thead><tbody><tr><td>master</td><td style=text-align:left>192.168.33.10</td><td style=text-align:left>CentOS7</td><td></td></tr><tr><td>node1</td><td style=text-align:left>192.168.33.11</td><td style=text-align:left>CentOS7</td><td></td></tr><tr><td>node2</td><td style=text-align:left>192.168.33.12</td><td style=text-align:left>CentOS7</td><td></td></tr><tr><td>node3</td><td style=text-align:left>192.168.33.13</td><td style=text-align:left>CentOS7</td><td></td></tr><tr><td>node4</td><td style=text-align:left>192.168.33.14</td><td style=text-align:left>CentOS7</td><td></td></tr><tr><td>node5</td><td style=text-align:left>192.168.33.15</td><td style=text-align:left>CentOS7</td><td></td></tr></tbody></table><h2 id=所有节点上操作>所有节点上操作</h2><div class="code-block code-line-numbers" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># cat preENV.sh</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#!/bin/bash</span>
</span></span><span class=line><span class=cl><span class=c1># 关闭防火墙</span>
</span></span><span class=line><span class=cl>systemctl stop firewalld <span class=o>&amp;&amp;</span> systemctl disable firewalld
</span></span><span class=line><span class=cl><span class=c1># 关闭 SELINUX</span>
</span></span><span class=line><span class=cl>setenforce <span class=m>0</span> <span class=o>&amp;&amp;</span> sed -i <span class=s2>&#34;s/SELINUX=enforcing/SELINUX=disabled/g&#34;</span> /etc/selinux/config
</span></span><span class=line><span class=cl><span class=c1># 关闭 Swap</span>
</span></span><span class=line><span class=cl>swapoff -a <span class=o>&amp;&amp;</span> sed -i <span class=s2>&#34;s/\/dev\/mapper\/centos-swap/\#\/dev\/mapper\/centos-swap/g&#34;</span> /etc/fstab
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># vim /etc/sysctl.d/k8s.conf</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># cat /etc/sysctl.d/k8s.conf</span>
</span></span><span class=line><span class=cl>net.bridge.bridge-nf-call-ip6tables <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>net.bridge.bridge-nf-call-iptables <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>net.ipv4.ip_forward <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># modprobe br_netfilter &amp;&amp; sysctl -p /etc/sysctl.d/k8s.conf</span>
</span></span><span class=line><span class=cl>net.bridge.bridge-nf-call-ip6tables <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>net.bridge.bridge-nf-call-iptables <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>net.ipv4.ip_forward <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># wget -O /etc/yum.repos.d/CentOS7-Aliyun.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span>
</span></span><span class=line><span class=cl>--2019-06-30 04:26:32--  http://mirrors.aliyun.com/repo/Centos-7.repo
</span></span><span class=line><span class=cl>Resolving mirrors.aliyun.com <span class=o>(</span>mirrors.aliyun.com<span class=o>)</span>... 116.177.250.229, 116.177.250.233, 60.28.226.4, ...
</span></span><span class=line><span class=cl>Connecting to mirrors.aliyun.com <span class=o>(</span>mirrors.aliyun.com<span class=o>)</span><span class=p>|</span>116.177.250.229<span class=p>|</span>:80... connected.
</span></span><span class=line><span class=cl>HTTP request sent, awaiting response... <span class=m>200</span> OK
</span></span><span class=line><span class=cl>Length: <span class=m>2523</span> <span class=o>(</span>2.5K<span class=o>)</span> <span class=o>[</span>application/octet-stream<span class=o>]</span>
</span></span><span class=line><span class=cl>Saving to: ‘/etc/yum.repos.d/CentOS7-Aliyun.repo’
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>100%<span class=o>[============================================================================</span>&gt;<span class=o>]</span> 2,523       --.-K/s   in 0s
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2019-06-30 04:26:32 <span class=o>(</span><span class=m>296</span> MB/s<span class=o>)</span> - ‘/etc/yum.repos.d/CentOS7-Aliyun.repo’ saved <span class=o>[</span>2523/2523<span class=o>]</span>
</span></span><span class=line><span class=cl>root@master ~<span class=o>]</span><span class=c1># sudo yum install -y yum-utils \</span>
</span></span><span class=line><span class=cl>  device-mapper-persistent-data <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  lvm2
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># sudo yum-config-manager \</span>
</span></span><span class=line><span class=cl>    --add-repo <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># yum install docker-ce -y</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># systemctl enable docker &amp;&amp; systemctl start docker</span>
</span></span><span class=line><span class=cl>Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># mkdir -p /etc/docker</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># sudo tee /etc/docker/daemon.json &lt;&lt;-&#39;EOF&#39;</span>
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;registry-mirrors&#34;</span>: <span class=o>[</span><span class=s2>&#34;https://gmjjwogo.mirror.aliyuncs.com&#34;</span><span class=o>]</span>,
</span></span><span class=line><span class=cl>  <span class=s2>&#34;exec-opts&#34;</span>: <span class=o>[</span><span class=s2>&#34;native.cgroupdriver=systemd&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;registry-mirrors&#34;</span>: <span class=o>[</span><span class=s2>&#34;https://gmjjwogo.mirror.aliyuncs.com&#34;</span><span class=o>]</span>,
</span></span><span class=line><span class=cl>  <span class=s2>&#34;exec-opts&#34;</span>: <span class=o>[</span><span class=s2>&#34;native.cgroupdriver=systemd&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># docker info |grep Cgroup</span>
</span></span><span class=line><span class=cl>Cgroup Driver: systemd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># # kube-proxy 开启 ipvs 的前置条件</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span>
</span></span><span class=line><span class=cl><span class=c1>#!/bin/bash</span>
</span></span><span class=line><span class=cl>modprobe -- ip_vs
</span></span><span class=line><span class=cl>modprobe -- ip_vs_rr
</span></span><span class=line><span class=cl>modprobe -- ip_vs_wrr
</span></span><span class=line><span class=cl>modprobe -- ip_vs_sh
</span></span><span class=line><span class=cl>modprobe -- nf_conntrack_ipv4
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span>
</span></span><span class=line><span class=cl>ip_vs_sh               <span class=m>12688</span>  <span class=m>0</span>
</span></span><span class=line><span class=cl>ip_vs_wrr              <span class=m>12697</span>  <span class=m>0</span>
</span></span><span class=line><span class=cl>ip_vs_rr               <span class=m>12600</span>  <span class=m>0</span>
</span></span><span class=line><span class=cl>ip_vs                 <span class=m>145497</span>  <span class=m>6</span> ip_vs_rr,ip_vs_sh,ip_vs_wrr
</span></span><span class=line><span class=cl>nf_conntrack_ipv4      <span class=m>15053</span>  <span class=m>2</span>
</span></span><span class=line><span class=cl>nf_defrag_ipv4         <span class=m>12729</span>  <span class=m>1</span> nf_conntrack_ipv4
</span></span><span class=line><span class=cl>nf_conntrack          <span class=m>133095</span>  <span class=m>7</span> ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_ipv4
</span></span><span class=line><span class=cl>libcrc32c              <span class=m>12644</span>  <span class=m>4</span> xfs,ip_vs,nf_nat,nf_conntrack
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># # 安装 kubernetes 初始化工具</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># # 使用阿里云的 kubernetes 源</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubernetes<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=nv>name</span><span class=o>=</span>Kubernetes
</span></span><span class=line><span class=cl><span class=nv>baseurl</span><span class=o>=</span>https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
</span></span><span class=line><span class=cl><span class=nv>enabled</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=nv>gpgcheck</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=nv>repo_gpgcheck</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=nv>gpgkey</span><span class=o>=</span>https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span><span class=line><span class=cl>EOF
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># # 安装 k8s 工具 1.15 版本</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># yum install -y kubelet kubeadm kubectl</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Installed:
</span></span><span class=line><span class=cl>  kubeadm.x86_64 0:1.15.0-0              kubectl.x86_64 0:1.15.0-0              kubelet.x86_64 0:1.15.0-0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Dependency Installed:
</span></span><span class=line><span class=cl>  conntrack-tools.x86_64 0:1.4.4-4.el7                       cri-tools.x86_64 0:1.12.0-0
</span></span><span class=line><span class=cl>  kubernetes-cni.x86_64 0:0.7.5-0                            libnetfilter_cthelper.x86_64 0:1.0.0-9.el7
</span></span><span class=line><span class=cl>  libnetfilter_cttimeout.x86_64 0:1.0.0-6.el7                libnetfilter_queue.x86_64 0:1.0.2-2.el7_2
</span></span><span class=line><span class=cl>  socat.x86_64 0:1.7.3.2-2.el7
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Complete!
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># # 启动 kubelet</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># systemctl enable kubelet &amp;&amp; systemctl start kubelet</span>
</span></span><span class=line><span class=cl>Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service.
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1>#</span></span></span></code></pre></div></div><h2 id=主节点操作>主节点操作</h2><div class="code-block code-line-numbers" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># vim installK8sMasterImage.sh</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># cat installK8sMasterImage.sh</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#!/bin/bash</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>set</span> -e
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>KUBE_VERSION</span><span class=o>=</span>v1.15.0
</span></span><span class=line><span class=cl><span class=nv>KUBE_PAUSE_VERSION</span><span class=o>=</span>3.1
</span></span><span class=line><span class=cl><span class=nv>ETCD_VERSION</span><span class=o>=</span>3.3.10
</span></span><span class=line><span class=cl><span class=nv>CORE_DNS_VERSION</span><span class=o>=</span>1.3.1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>GCR_URL</span><span class=o>=</span>k8s.gcr.io
</span></span><span class=line><span class=cl><span class=nv>ALIYUN_URL</span><span class=o>=</span>registry.cn-hangzhou.aliyuncs.com/google_containers
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>images</span><span class=o>=(</span>kube-proxy:<span class=si>${</span><span class=nv>KUBE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>kube-scheduler:<span class=si>${</span><span class=nv>KUBE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>kube-controller-manager:<span class=si>${</span><span class=nv>KUBE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>kube-apiserver:<span class=si>${</span><span class=nv>KUBE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>pause:<span class=si>${</span><span class=nv>KUBE_PAUSE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>etcd:<span class=si>${</span><span class=nv>ETCD_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>coredns:<span class=si>${</span><span class=nv>CORE_DNS_VERSION</span><span class=si>}</span><span class=o>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> imageName in <span class=si>${</span><span class=nv>images</span><span class=p>[@]</span><span class=si>}</span> <span class=p>;</span> <span class=k>do</span>
</span></span><span class=line><span class=cl>  docker pull <span class=nv>$ALIYUN_URL</span>/<span class=nv>$imageName</span>
</span></span><span class=line><span class=cl>  docker tag  <span class=nv>$ALIYUN_URL</span>/<span class=nv>$imageName</span> <span class=nv>$GCR_URL</span>/<span class=nv>$imageName</span>
</span></span><span class=line><span class=cl>  docker rmi <span class=nv>$ALIYUN_URL</span>/<span class=nv>$imageName</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># chmod +x installK8sMasterImage.sh &amp;&amp; ./installK8sMasterImage.sh</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>root@master install<span class=o>]</span><span class=c1># kubeadm init --kubernetes-version=v1.15.0 --apiserver-advertise-address=192.168.33.10 --pod-network-cidr=10.244.0.0/16</span>
</span></span><span class=line><span class=cl><span class=o>[</span>init<span class=o>]</span> Using Kubernetes version: v1.15.0
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Running pre-flight checks
</span></span><span class=line><span class=cl>	<span class=o>[</span>WARNING Hostname<span class=o>]</span>: hostname <span class=s2>&#34;master&#34;</span> could not be reached
</span></span><span class=line><span class=cl>	<span class=o>[</span>WARNING Hostname<span class=o>]</span>: hostname <span class=s2>&#34;master&#34;</span>: lookup master on 10.0.2.3:53: no such host
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Pulling images required <span class=k>for</span> setting up a Kubernetes cluster
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> This might take a minute or two, depending on the speed of your internet connection
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> You can also perform this action in beforehand using <span class=s1>&#39;kubeadm config images pull&#39;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet environment file with flags to file <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet configuration to file <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Activating the kubelet service
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Using certificateDir folder <span class=s2>&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;front-proxy-ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;front-proxy-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> apiserver serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local<span class=o>]</span> and IPs <span class=o>[</span>10.96.0.1 192.168.33.10<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver-kubelet-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/server&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> etcd/server serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>master localhost<span class=o>]</span> and IPs <span class=o>[</span>192.168.33.10 127.0.0.1 ::1<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/healthcheck-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver-etcd-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/peer&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> etcd/peer serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>master localhost<span class=o>]</span> and IPs <span class=o>[</span>192.168.33.10 127.0.0.1 ::1<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;sa&#34;</span> key and public key
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Using kubeconfig folder <span class=s2>&#34;/etc/kubernetes&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;admin.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;kubelet.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;controller-manager.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;scheduler.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Using manifest folder <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-scheduler&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>etcd<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=nb>local</span> etcd in <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>wait-control-plane<span class=o>]</span> Waiting <span class=k>for</span> the kubelet to boot up the control plane as static Pods from directory <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
</span></span><span class=line><span class=cl><span class=o>[</span>apiclient<span class=o>]</span> All control plane components are healthy after 26.502984 seconds
</span></span><span class=line><span class=cl><span class=o>[</span>upload-config<span class=o>]</span> Storing the configuration used in ConfigMap <span class=s2>&#34;kubeadm-config&#34;</span> in the <span class=s2>&#34;kube-system&#34;</span> Namespace
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet<span class=o>]</span> Creating a ConfigMap <span class=s2>&#34;kubelet-config-1.15&#34;</span> in namespace kube-system with the configuration <span class=k>for</span> the kubelets in the cluster
</span></span><span class=line><span class=cl><span class=o>[</span>upload-certs<span class=o>]</span> Skipping phase. Please see --upload-certs
</span></span><span class=line><span class=cl><span class=o>[</span>mark-control-plane<span class=o>]</span> Marking the node master as control-plane by adding the label <span class=s2>&#34;node-role.kubernetes.io/master=&#39;&#39;&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>mark-control-plane<span class=o>]</span> Marking the node master as control-plane by adding the taints <span class=o>[</span>node-role.kubernetes.io/master:NoSchedule<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Using token: z1uxfl.z8l2uo9v8x3dtdcu
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span class=k>for</span> nodes to get long term certificate credentials
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow certificate rotation <span class=k>for</span> all node client certificates in the cluster
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Creating the <span class=s2>&#34;cluster-info&#34;</span> ConfigMap in the <span class=s2>&#34;kube-public&#34;</span> namespace
</span></span><span class=line><span class=cl><span class=o>[</span>addons<span class=o>]</span> Applied essential addon: CoreDNS
</span></span><span class=line><span class=cl><span class=o>[</span>addons<span class=o>]</span> Applied essential addon: kube-proxy
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Your Kubernetes control-plane has initialized successfully!
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>To start using your cluster, you need to run the following as a regular user:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>  sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>  sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>You should now deploy a pod network to the cluster.
</span></span><span class=line><span class=cl>Run <span class=s2>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span class=line><span class=cl>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>kubeadm join 192.168.33.10:6443 --token z1uxfl.z8l2uo9v8x3dtdcu <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --discovery-token-ca-cert-hash sha256:5c725b5b384221d25aed03a02a142fe2442d76f6362673b72f349abffb18b6f2
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1>#</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># mkdir -p $HOME/.kube</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># sudo chown $(id -u):$(id -g) $HOME/.kube/config</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># kubectl get pod -n kube-system -owide</span>
</span></span><span class=line><span class=cl>NAME                             READY   STATUS    RESTARTS   AGE   IP          NODE     NOMINATED NODE   READINESS GATES
</span></span><span class=line><span class=cl>coredns-5c98db65d4-9g7dj         0/1     Pending   <span class=m>0</span>          39s   &lt;none&gt;      &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>coredns-5c98db65d4-f6h7d         0/1     Pending   <span class=m>0</span>          39s   &lt;none&gt;      &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>etcd-master                      1/1     Running   <span class=m>0</span>          57s   10.0.2.15   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-apiserver-master            1/1     Running   <span class=m>0</span>          57s   10.0.2.15   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-controller-manager-master   1/1     Running   <span class=m>0</span>          57s   10.0.2.15   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-proxy-n9tql                 1/1     Running   <span class=m>0</span>          39s   10.0.2.15   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-scheduler-master            1/1     Running   <span class=m>0</span>          57s   10.0.2.15   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># wget https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml</span>
</span></span><span class=line><span class=cl>--2019-06-30 06:47:53--  https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml
</span></span><span class=line><span class=cl>Resolving raw.githubusercontent.com <span class=o>(</span>raw.githubusercontent.com<span class=o>)</span>... 151.101.228.133
</span></span><span class=line><span class=cl>Connecting to raw.githubusercontent.com <span class=o>(</span>raw.githubusercontent.com<span class=o>)</span><span class=p>|</span>151.101.228.133<span class=p>|</span>:443... connected.
</span></span><span class=line><span class=cl>HTTP request sent, awaiting response... <span class=m>200</span> OK
</span></span><span class=line><span class=cl>Length: <span class=m>12306</span> <span class=o>(</span>12K<span class=o>)</span> <span class=o>[</span>text/plain<span class=o>]</span>
</span></span><span class=line><span class=cl>Saving to: ‘kube-flannel.yml’
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>100%<span class=o>[==============================================================================================</span>&gt;<span class=o>]</span> 12,306      51.3KB/s   in 0.2s
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2019-06-30 06:47:57 <span class=o>(</span>51.3 KB/s<span class=o>)</span> - ‘kube-flannel.yml’ saved <span class=o>[</span>12306/12306<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># ll</span>
</span></span><span class=line><span class=cl>total <span class=m>24</span>
</span></span><span class=line><span class=cl>-rwxr-xr-x. <span class=m>1</span> root root   <span class=m>580</span> Jun <span class=m>30</span> 05:21 installK8sMasterImage.sh
</span></span><span class=line><span class=cl>-rw-r--r--. <span class=m>1</span> root root <span class=m>12306</span> Jun <span class=m>30</span> 05:26 kube-flannel.yml
</span></span><span class=line><span class=cl>-rwxr-xr-x. <span class=m>1</span> root root   <span class=m>294</span> Jun <span class=m>30</span> 04:20 preENV.sh
</span></span><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># kubectl apply -f kube-flannel.yml</span>
</span></span><span class=line><span class=cl>podsecuritypolicy.extensions/psp.flannel.unprivileged created
</span></span><span class=line><span class=cl>clusterrole.rbac.authorization.k8s.io/flannel created
</span></span><span class=line><span class=cl>clusterrolebinding.rbac.authorization.k8s.io/flannel created
</span></span><span class=line><span class=cl>serviceaccount/flannel created
</span></span><span class=line><span class=cl>configmap/kube-flannel-cfg created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-amd64 created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-arm64 created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-arm created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-flannel-ds-ppc64le created
</span></span><span class=line><span class=cl>daemonset.extensions/kube-fla<span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># kubectl get pod -n kube-system -owide</span>
</span></span><span class=line><span class=cl>NAME                             READY   STATUS    RESTARTS   AGE     IP           NODE     NOMINATED NODE   READINESS GATES
</span></span><span class=line><span class=cl>coredns-5c98db65d4-9g7dj         1/1     Running   <span class=m>0</span>          5m42s   10.244.0.3   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>coredns-5c98db65d4-f6h7d         1/1     Running   <span class=m>0</span>          5m42s   10.244.0.2   master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>etcd-master                      1/1     Running   <span class=m>0</span>          6m      10.0.2.15    master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-apiserver-master            1/1     Running   <span class=m>0</span>          6m      10.0.2.15    master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-controller-manager-master   1/1     Running   <span class=m>0</span>          6m      10.0.2.15    master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-flannel-ds-amd64-lbprc      1/1     Running   <span class=m>0</span>          84s     10.0.2.15    master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-proxy-n9tql                 1/1     Running   <span class=m>0</span>          5m42s   10.0.2.15    master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl>kube-scheduler-master            1/1     Running   <span class=m>0</span>          6m      10.0.2.15    master   &lt;none&gt;           &lt;none&gt;
</span></span><span class=line><span class=cl><span class=o>[</span>root@master install<span class=o>]</span><span class=c1># # 查看当前集群状态</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># kubectl get node -A</span>
</span></span><span class=line><span class=cl>NAME     STATUS   ROLES    AGE     VERSION
</span></span><span class=line><span class=cl>master   Ready    master   6m29s   v1.15.0
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1>#</span></span></span></code></pre></div></div><h2 id=各-node-节点上处理>各 Node 节点上处理</h2><div class="code-block code-line-numbers" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@node2 install<span class=o>]</span><span class=c1># vim installK8sNodeImage.sh</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@node5 install<span class=o>]</span><span class=c1># cat installK8sNodeImage.sh</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#!/bin/bash</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>set</span> -e
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>KUBE_VERSION</span><span class=o>=</span>v1.15.0
</span></span><span class=line><span class=cl><span class=nv>KUBE_PAUSE_VERSION</span><span class=o>=</span>3.1
</span></span><span class=line><span class=cl><span class=nv>CORE_DNS_VERSION</span><span class=o>=</span>1.3.1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>GCR_URL</span><span class=o>=</span>k8s.gcr.io
</span></span><span class=line><span class=cl><span class=nv>ALIYUN_URL</span><span class=o>=</span>registry.cn-hangzhou.aliyuncs.com/google_containers
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>images</span><span class=o>=(</span>kube-proxy:<span class=si>${</span><span class=nv>KUBE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>pause:<span class=si>${</span><span class=nv>KUBE_PAUSE_VERSION</span><span class=si>}</span>
</span></span><span class=line><span class=cl>coredns:<span class=si>${</span><span class=nv>CORE_DNS_VERSION</span><span class=si>}</span><span class=o>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> imageName in <span class=si>${</span><span class=nv>images</span><span class=p>[@]</span><span class=si>}</span> <span class=p>;</span> <span class=k>do</span>
</span></span><span class=line><span class=cl>  docker pull <span class=nv>$ALIYUN_URL</span>/<span class=nv>$imageName</span>
</span></span><span class=line><span class=cl>  docker tag  <span class=nv>$ALIYUN_URL</span>/<span class=nv>$imageName</span> <span class=nv>$GCR_URL</span>/<span class=nv>$imageName</span>
</span></span><span class=line><span class=cl>  docker rmi <span class=nv>$ALIYUN_URL</span>/<span class=nv>$imageName</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@node1 ~<span class=o>]</span><span class=c1># chmod +x installK8sNodeImage.sh  &amp;&amp; ./installK8sNodeImage.sh</span>
</span></span><span class=line><span class=cl>v1.15.0: Pulling from google_containers/kube-proxy
</span></span><span class=line><span class=cl>39fafc05754f: Pull <span class=nb>complete</span>
</span></span><span class=line><span class=cl>db3f71d0eb90: Pull <span class=nb>complete</span>
</span></span><span class=line><span class=cl>b593bfa65f6f: Pull <span class=nb>complete</span>
</span></span><span class=line><span class=cl>Digest: sha256:7b94921f1c64876d3663698ade724fce79b417b32f0e1053976ca68a18fc0cba
</span></span><span class=line><span class=cl>Status: Downloaded newer image <span class=k>for</span> registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.0
</span></span><span class=line><span class=cl>Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.0
</span></span><span class=line><span class=cl>Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy@sha256:7b94921f1c64876d3663698ade724fce79b417b32f0e1053976ca68a18fc0cba
</span></span><span class=line><span class=cl>3.1: Pulling from google_containers/pause
</span></span><span class=line><span class=cl>cf9202429979: Pull <span class=nb>complete</span>
</span></span><span class=line><span class=cl>Digest: sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca
</span></span><span class=line><span class=cl>Status: Downloaded newer image <span class=k>for</span> registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
</span></span><span class=line><span class=cl>Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
</span></span><span class=line><span class=cl>Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/pause@sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca
</span></span><span class=line><span class=cl>1.3.1: Pulling from google_containers/coredns
</span></span><span class=line><span class=cl>e0daa8927b68: Pull <span class=nb>complete</span>
</span></span><span class=line><span class=cl>3928e47de029: Pull <span class=nb>complete</span>
</span></span><span class=line><span class=cl>Digest: sha256:638adb0319813f2479ba3642bbe37136db8cf363b48fb3eb7dc8db634d8d5a5b
</span></span><span class=line><span class=cl>Status: Downloaded newer image <span class=k>for</span> registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1
</span></span><span class=line><span class=cl>Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1
</span></span><span class=line><span class=cl>Untagged: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns@sha256:638adb0319813f2479ba3642bbe37136db8cf363b48fb3eb7dc8db634d8d5a5b
</span></span><span class=line><span class=cl><span class=o>[</span>root@node1 ~<span class=o>]</span><span class=c1>#</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@node5 install<span class=o>]</span><span class=c1># # Node 加入集群</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@node1 install<span class=o>]</span><span class=c1># kubeadm join 192.168.33.10:6443 --token sofcoc.j1it9gvn4uxpduo5 \</span>
</span></span><span class=line><span class=cl>&gt;     --discovery-token-ca-cert-hash sha256:3a9b79bd92f66a6284322ade27732932888c0f99884596d5f2c9a03d272e475b
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Running pre-flight checks
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Reading configuration from the cluster...
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> FYI: You can look at this config file with <span class=s1>&#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Downloading configuration <span class=k>for</span> the kubelet from the <span class=s2>&#34;kubelet-config-1.15&#34;</span> ConfigMap in the kube-system namespace
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet configuration to file <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet environment file with flags to file <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Activating the kubelet service
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Waiting <span class=k>for</span> the kubelet to perform the TLS Bootstrap...
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>This node has joined the cluster:
</span></span><span class=line><span class=cl>* Certificate signing request was sent to apiserver and a response was received.
</span></span><span class=line><span class=cl>* The Kubelet was informed of the new secure connection details.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Run <span class=s1>&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@node1 install<span class=o>]</span><span class=c1>#</span></span></span></code></pre></div></div><h2 id=master-节点操作>master 节点操作</h2><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># #将 master 节点也作为工作节点进行 pod 部署</span>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master ~<span class=o>]</span><span class=c1># kubectl taint nodes master node-role.kubernetes.io/master-</span>
</span></span><span class=line><span class=cl>node/master untainted</span></span></code></pre></div></div><h2 id=打-label>打 label</h2><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl label node master nodename=master</span>
</span></span><span class=line><span class=cl>node/master labeled
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl label node node1 nodename=node1</span>
</span></span><span class=line><span class=cl>node/node1 labeled
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl label node node2 nodename=node2</span>
</span></span><span class=line><span class=cl>node/node2 labeled
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl label node node3 nodename=node3</span>
</span></span><span class=line><span class=cl>node/node3 labeled
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl label node node4 nodename=node4</span>
</span></span><span class=line><span class=cl>node/node4 labeled
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl label node node5 nodename=node5</span>
</span></span><span class=line><span class=cl>node/node5 labeled</span></span></code></pre></div></div><h2 id=测试>测试</h2><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vim nginx-deployment.yaml</span></span></code></pre></div></div><div class="code-block code-line-numbers" style="counter-reset:code-block 0"><div class="code-header language-yaml"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nginx-deployment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>nginx:1.7.9</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>imagePullPolicy</span><span class=p>:</span><span class=w> </span><span class=l>IfNotPresent</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>web</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>protocol</span><span class=p>:</span><span class=w> </span><span class=l>TCP</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>nodeSelector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>nodename</span><span class=p>:</span><span class=w> </span><span class=l>master</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nginx-service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>targetPort</span><span class=p>:</span><span class=w> </span><span class=m>8080</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>web</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>app-name</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>extensions/v1beta1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Ingress</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>default</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>rules</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=l>c4.k8s.com</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>http</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>backend</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>serviceName</span><span class=p>:</span><span class=w> </span><span class=l>nginx-service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>servicePort</span><span class=p>:</span><span class=w> </span><span class=m>8080</span></span></span></code></pre></div></div><div class="code-block code-line-numbers open" style="counter-reset:code-block 0"><div class="code-header language-shell"><span class=code-title><i class="arrow fas fa-angle-right fa-fw" aria-hidden=true></i></span>
<span class=ellipses><i class="fas fa-ellipsis-h fa-fw" aria-hidden=true></i></span>
<span class=copy title=复制到剪贴板><i class="far fa-copy fa-fw" aria-hidden=true></i></span></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl apply -f nginx-deployment.yaml</span>
</span></span><span class=line><span class=cl>deployment.apps/nginx-deployment created
</span></span><span class=line><span class=cl>service/nginx-service created
</span></span><span class=line><span class=cl>ingress.extensions/nginx created
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl get service/nginx-service</span>
</span></span><span class=line><span class=cl>NAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT<span class=o>(</span>S<span class=o>)</span>   AGE
</span></span><span class=line><span class=cl>nginx-service   ClusterIP   10.100.2.78   &lt;none&gt;        80/TCP    38s
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl get ing</span>
</span></span><span class=line><span class=cl>NAME    HOSTS        ADDRESS   PORTS   AGE
</span></span><span class=line><span class=cl>nginx   c4.k8s.com             <span class=m>80</span>      4m5s
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># wget c4.k8s.com</span>
</span></span><span class=line><span class=cl>--2019-06-30 07:12:18--  http://c4.k8s.com/
</span></span><span class=line><span class=cl>Resolving c4.k8s.com <span class=o>(</span>c4.k8s.com<span class=o>)</span>... 208.73.211.177, 208.73.210.202, 208.73.211.165, ...
</span></span><span class=line><span class=cl>Connecting to c4.k8s.com <span class=o>(</span>c4.k8s.com<span class=o>)</span><span class=p>|</span>208.73.211.177<span class=p>|</span>:80... connected.
</span></span><span class=line><span class=cl>HTTP request sent, awaiting response... <span class=m>302</span> Found : Moved Temporarily
</span></span><span class=line><span class=cl>Location: http://1223.dragonparking.com/?site<span class=o>=</span>c4.k8s.com <span class=o>[</span>following<span class=o>]</span>
</span></span><span class=line><span class=cl>--2019-06-30 07:12:19--  http://1223.dragonparking.com/?site<span class=o>=</span>c4.k8s.com
</span></span><span class=line><span class=cl>Resolving 1223.dragonparking.com <span class=o>(</span>1223.dragonparking.com<span class=o>)</span>... 46.51.238.1
</span></span><span class=line><span class=cl>Connecting to 1223.dragonparking.com <span class=o>(</span>1223.dragonparking.com<span class=o>)</span><span class=p>|</span>46.51.238.1<span class=p>|</span>:80... connected.
</span></span><span class=line><span class=cl>HTTP request sent, awaiting response... <span class=m>302</span> Moved Temporarily
</span></span><span class=line><span class=cl>Location: http://park.zunmi.cn/?acct<span class=o>=</span>1223<span class=p>&amp;</span><span class=nv>site</span><span class=o>=</span>c4.k8s.com <span class=o>[</span>following<span class=o>]</span>
</span></span><span class=line><span class=cl>--2019-06-30 07:12:21--  http://park.zunmi.cn/?acct<span class=o>=</span>1223<span class=p>&amp;</span><span class=nv>site</span><span class=o>=</span>c4.k8s.com
</span></span><span class=line><span class=cl>Resolving park.zunmi.cn <span class=o>(</span>park.zunmi.cn<span class=o>)</span>... 52.197.205.2
</span></span><span class=line><span class=cl>Connecting to park.zunmi.cn <span class=o>(</span>park.zunmi.cn<span class=o>)</span><span class=p>|</span>52.197.205.2<span class=p>|</span>:80... connected.
</span></span><span class=line><span class=cl>HTTP request sent, awaiting response... <span class=m>200</span> OK
</span></span><span class=line><span class=cl>Length: <span class=m>1020</span> <span class=o>[</span>text/html<span class=o>]</span>
</span></span><span class=line><span class=cl>Saving to: ‘index.html’
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>100%<span class=o>[======================================================================================================================================</span>&gt;<span class=o>]</span> 1,020       --.-K/s   in 0s
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2019-06-30 07:12:22 <span class=o>(</span>93.5 MB/s<span class=o>)</span> - ‘index.html’ saved <span class=o>[</span>1020/1020<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># ll</span>
</span></span><span class=line><span class=cl>total <span class=m>8</span>
</span></span><span class=line><span class=cl>-rw-r--r--. <span class=m>1</span> root root <span class=m>1020</span> May  <span class=m>6</span> 23:28 index.html
</span></span><span class=line><span class=cl>-rw-r--r--. <span class=m>1</span> root root  <span class=m>908</span> Jun <span class=m>30</span> 07:07 nginx-deployment.yaml
</span></span><span class=line><span class=cl><span class=o>[</span>root@master temp<span class=o>]</span><span class=c1># kubectl delete -f nginx-deployment.yaml</span>
</span></span><span class=line><span class=cl>deployment.apps <span class=s2>&#34;nginx-deployment&#34;</span> deleted
</span></span><span class=line><span class=cl>service <span class=s2>&#34;nginx-service&#34;</span> deleted
</span></span><span class=line><span class=cl>ingress.extensions <span class=s2>&#34;nginx&#34;</span> deleted</span></span></code></pre></div></div></div><div class=disclaimer><h2>免责声明</h2><p>本文仅代表个人观点，与本人所供职的公司无任何关系。</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2019-06-30</span></div><div class=post-info-license><span><a rel=license href=http://creativecommons.org/licenses/by-nc/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by-nc/4.0/80x15.png></a></span></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/index.md target=_blank>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=x data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-title="K8s 1.15.0 安装记录" data-via=guzhongren data-hashtags=kubernetes,install,cluster,nginx,service><i class="fab fa-x-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Threads" data-sharer=threads data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-title="K8s 1.15.0 安装记录"><i class="fab fa-threads fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-hashtag=kubernetes><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Hacker News" data-sharer=hackernews data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-title="K8s 1.15.0 安装记录"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Line" data-sharer=line data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-title="K8s 1.15.0 安装记录"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@15.14.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-title="K8s 1.15.0 安装记录" data-image="https://images.pexels.com/photos/3872067/pexels-photo-3872067.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Diaspora" data-sharer=diaspora data-url=https://guzhongren.github.io/2019/06/k8s-1.15.0-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95.zh/ data-title="K8s 1.15.0 安装记录" data-description><i class="fab fa-diaspora fa-fw" aria-hidden=true></i></a><a href="https://t.me/share/url?url=https%3a%2f%2fguzhongren.github.io%2f2019%2f06%2fk8s-1.15.0-%25E5%25AE%2589%25E8%25A3%2585%25E8%25AE%25B0%25E5%25BD%2595.zh%2f&amp;text=K8s%201.15.0%20%e5%ae%89%e8%a3%85%e8%ae%b0%e5%bd%95" target=_blank title="分享到 Telegram"><i class="fab fa-telegram fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/kubernetes/>Kubernetes</a>,&nbsp;<a href=/tags/install/>Install</a>,&nbsp;<a href=/tags/cluster/>Cluster</a>,&nbsp;<a href=/tags/nginx/>Nginx</a>,&nbsp;<a href=/tags/service/>Service</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/2019/06/harbor-%E5%AE%89%E8%A3%85%E5%B0%8F%E8%AE%B0.zh/ class=prev rel=prev title="Harbor 安装小记"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Harbor 安装小记</a>
<a href=/2019/09/golang-with-sqllite-practice.zh/ class=next rel=next title="Golang With SQLLite Practice">Golang With SQLLite Practice<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=utterances class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>utterances</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>友情链接:<div style=display:flex;justify-content:center;align-items:center><a style="display:flex;justify-content:center;align-items:center;margin:0 1rem" href=https://yihaimen.github.io><span style=display:flex;justify-content:center;align-items:center><img style=height:24px src=https://yihaimen.github.io/images/avatar.png><span>易海门的博客</span></span></a><a style="display:flex;justify-content:center;align-items:center;margin:0 1rem" href=https://bytewars.cc><span style=display:flex;justify-content:center;align-items:center><img style=height:24px src=https://bytewars.github.io/images/avatar.png><span>ByteWars社区</span></span></a></div></div><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.145.0">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.3.1-DEV"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2020 - 2026</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=guzhongren@live.cn target=_blank>谷中仁</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i></a></div><div id=fixed-buttons-hidden><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@5.20.2/dist/lite/builds/browser.umd.min.js></script><script src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script src=https://cdn.jsdelivr.net/npm/twemoji@14.0.2/dist/twemoji.min.js></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js></script><script>window.config={comment:{utterances:{darkTheme:"github-dark",issueTerm:"title",label:"utterances",lightTheme:"github-light",repo:"guzhongren/guzhongren.github.io"}},search:{algoliaAppID:"8FBSWQTAD1",algoliaIndex:"index.zh-cn",algoliaSearchKey:"f8e94db6f14a6320dcdcb4db3f7256aa",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:30,type:"algolia"},twemoji:!0}</script><script src=/js/theme.min.js></script></body></html>