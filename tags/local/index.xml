<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Local - 标签 - 谷中仁的博客</title><link>https://guzhongren.github.io/tags/local/</link><description>Local - 标签 - 谷中仁的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>guzhongren@live.cn (谷中仁)</managingEditor><webMaster>guzhongren@live.cn (谷中仁)</webMaster><copyright>Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 11 Feb 2025 22:31:58 +0800</lastBuildDate><atom:link href="https://guzhongren.github.io/tags/local/" rel="self" type="application/rss+xml"/><item><title>本地跑deepseek 7b模型</title><link>https://guzhongren.github.io/2025/02/%E6%9C%AC%E5%9C%B0%E8%B7%91deepseek-7b%E6%A8%A1%E5%9E%8B/</link><pubDate>Tue, 11 Feb 2025 22:31:58 +0800</pubDate><author>谷中仁</author><guid>https://guzhongren.github.io/2025/02/%E6%9C%AC%E5%9C%B0%E8%B7%91deepseek-7b%E6%A8%A1%E5%9E%8B/</guid><description><![CDATA[<div class="featured-image">
                <img src="https://images.unsplash.com/photo-1671227498016-93aa927686f8?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=1074&amp;q=80" referrerpolicy="no-referrer">
            </div><h2 id="背景">背景</h2>
<p>最近，Deepseek 因其卓越的性能和高效的推理速度在技术圈内引起了广泛关注。</p>
<p>Deepseek 采用了先进的算法(使用汇编和 CUDA 混编的方式调用 GPU)和训练方法(蒸馏)，不仅显著提升了推理速度，还降低了对硬件配置的要求，使其能够在更多设备上运行。</p>
<p>然而，使用在线 Deepseek 服务时，用户可能会遇到“服务器繁忙，请稍后再试”的问题。</p>
<p>作为程序员，我们自然不能忍受这种情况，因此本文将指导你如何在本地搭建 Deepseek 模型。</p>
<h2 id="搭建步骤">搭建步骤</h2>
<h3 id="所需软件及环境">所需软件及环境</h3>
<h4 id="环境">环境</h4>
<ul>
<li><strong>操作系统</strong>: MacOS M1 (Sequoia [Version 15.3])</li>
</ul>
<h4 id="软件">软件</h4>
<ul>
<li><strong><a href="https://ollama.com/" target="_blank" rel="noopener noreffer ">Ollama</a></strong>: 用于管理和运行大模型。</li>
<li><strong><a href="https://chatboxai.app/" target="_blank" rel="noopener noreffer ">Chatbox AI</a></strong>: 提供与大模型交互的界面。</li>
</ul>
<h3 id="安装步骤">安装步骤</h3>
<h4 id="安装-ollama">安装 Ollama</h4>
<p>Ollama 可以通过命令行或手动下载安装包进行安装。手动安装后，系统会自动启动 Ollama 服务；而通过命令行安装后，则需要手动启动服务。</p>
<div class="code-block code-line-numbers open" style="counter-reset: code-block 0">
    <div class="code-header language-sh">
        <span class="code-title"><i class="arrow fas fa-angle-right fa-fw" aria-hidden="true"></i></span>
        <span class="ellipses"><i class="fas fa-ellipsis-h fa-fw" aria-hidden="true"></i></span>
        <span class="copy" title="复制到剪贴板"><i class="far fa-copy fa-fw" aria-hidden="true"></i></span>
    </div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">brew install ollama
</span></span><span class="line"><span class="cl"><span class="c1"># 安装完成后，启动 Ollama 服务</span>
</span></span><span class="line"><span class="cl">ollama serve</span></span></code></pre></div></div>
<h4 id="运行-deepseek模型">运行 deepseek模型</h4>
<ol>
<li>访问 Ollama 模型库，搜索 deepseek。</li>
<li>选择 deepseek-r1 模型，并选择 7b 版本。</li>
<li>点击复制按钮，将命令行粘贴到终端中运行。Ollama 将自动拉取并启动该模型。</li>
</ol>
<div class="code-block code-line-numbers open" style="counter-reset: code-block 0">
    <div class="code-header language-sh">
        <span class="code-title"><i class="arrow fas fa-angle-right fa-fw" aria-hidden="true"></i></span>
        <span class="ellipses"><i class="fas fa-ellipsis-h fa-fw" aria-hidden="true"></i></span>
        <span class="copy" title="复制到剪贴板"><i class="far fa-copy fa-fw" aria-hidden="true"></i></span>
    </div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">ollama run deepseek-r1:7b</span></span></code></pre></div></div>
<h4 id="安装-chatbox">安装 Chatbox</h4>
<p>Chatbox 是与大模型进行交互的界面。你可以选择直接安装软件或通过 Docker 运行。推荐使用软件安装，以便快速启动和操作。</p>
<p>可安装软件或者通过docker 运行，推荐软件安装，可以快速启动软件来提速。</p>
<h4 id="配置">配置</h4>
<p>Chatbox 安装完成并且 deepseek 大模型运行起来后，在 Chatbox -&gt; Settings 中选择本地启动的模型即可。</p>
<h2 id="总结">总结</h2>
<p>随着人工智能技术的快速发展，社会分工可能会发生显著变化, 最明显的是人工智能会淘汰掉社会分工的中间层。</p>
<p>未来的趋势可能是：要么成为顶层的规则设计者，要么成为底层的实践者。通过本地搭建和运行 Deepseek 模型，我们不仅能够避免在线服务的限制，还能更深入地理解和掌握这一前沿技术。</p>
<h2 id="引用">引用</h2>
<ul>
<li><a href="https://guzhongren.github.io/" target="_blank" rel="noopener noreffer ">博客:https://guzhongren.github.io/</a></li>
<li><a href="https://www.deepseek.com/" target="_blank" rel="noopener noreffer ">Deepseek:https://www.deepseek.com/</a></li>
<li><a href="https://ollama.com/" target="_blank" rel="noopener noreffer ">Ollama:https://ollama.com/</a></li>
<li><a href="https://chatboxai.app/" target="_blank" rel="noopener noreffer ">Chatbox AI:https://chatboxai.app/</a></li>
</ul>
<h2 id="免责声明">免责声明</h2>
<p>本文仅代表个人观点，与本人所供职的公司无任何关系。</p>
<hr>
<p><img src="https://cdn.jsdelivr.net/gh/guzhongren/data-hosting@master/20210819/wechat.ae9zxgscqcg.png" alt="谷哥说-微信公众号" /></p>
]]></description></item></channel></rss>